{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from multiview_prediction_toolkit.cameras.derived_cameras import MetashapeCameraSet\n",
    "from multiview_prediction_toolkit.meshes import TexturedPhotogrammetryMesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set values for constants\n",
    "All edits should be able to be made below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHORT_NAME = \"delta\"\n",
    "LONG_NAME = \"DeltaB\"\n",
    "\n",
    "GEO_FILENAME = \"/ofo-share/str-disp_drone-data-partial/cross-site/crowns-w-field-labels/crowns_drone_w_field_data.gpkg\"\n",
    "UPDATED_GEO_FILNAME = \"/ofo-share/repos-david/semantic-mesh-pytorch3d/data/species-class-seed-kernel/crowns_drone_w_field_data.geojson\"\n",
    "\n",
    "MESH_FILENAME = glob(f\"/ofo-share/repos-david/semantic-mesh-pytorch3d/data/species-class-seed-kernel/metashape_exports/{LONG_NAME}*_w-mesh_exports/{LONG_NAME}*_w-mesh.ply\")[0]\n",
    "CAMERA_FILENAME = glob(f\"/ofo-share/repos-david/semantic-mesh-pytorch3d/data/species-class-seed-kernel/metashape_exports/{LONG_NAME}*_w-mesh_exports/{LONG_NAME}*_w-mesh.xml\")[0]\n",
    "\n",
    "DEM_FILE = f\"/ofo-share/str-disp_drone-data-partial/cross-site/dtms/photogrammetry/{SHORT_NAME}.tif\"\n",
    "IMAGE_FOLDER = f\"/ofo-share/str-disp_drone-data-partial/str-disp_drone-data_imagery-missions/{LONG_NAME}/{LONG_NAME}_120m/\"\n",
    "\n",
    "DOWNSAMPLED_MESH_FILENAME = f\"/ofo-share/repos-david/semantic-mesh-pytorch3d/data/species-class-seed-kernel/intermediate_meshes/{SHORT_NAME}_downsampled.ply\" \n",
    "LABELED_MESH_FILENAME = f\"/ofo-share/repos-david/semantic-mesh-pytorch3d/data/species-class-seed-kernel/intermediate_meshes/{SHORT_NAME}_labeled.ply\" \n",
    "\n",
    "HEIGHT_ABOVE_GROUND_THRESH = 2\n",
    "MESH_DOWNSAMPLE_TARGET = 0.25\n",
    "RENDER_IMAGE_SCALE = 0.25\n",
    "BUFFER_RADIUS_METER = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geospatial processing\n",
    "\n",
    "Preprocess the geospatial data to be as expected. Here we set all trees that are marked as dead to the SNAG class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated any trees marked as dead to the SNAG class\n",
    "gdf = gpd.read_file(GEO_FILENAME)\n",
    "dead_trees = np.logical_not(gdf[\"live_observed\"].to_numpy().astype(bool))\n",
    "gdf.loc[dead_trees, \"species_observed\"] = \"SNAG\"\n",
    "gdf.to_file(UPDATED_GEO_FILNAME)\n",
    "\n",
    "site_gdf = gdf.groupby(\"stem_map_name\")\n",
    "gdf.loc[gdf[\"fire\"] == SHORT_NAME].plot(\"species_observed\", legend=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a mesh and downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Create a mesh to downsample\n",
    "    mesh = TexturedPhotogrammetryMesh(\n",
    "        MESH_FILENAME,\n",
    "        downsample_target=MESH_DOWNSAMPLE_TARGET,\n",
    "    )\n",
    "    # Save the downsampled mesh \n",
    "    mesh.save_mesh(DOWNSAMPLED_MESH_FILENAME, save_vert_texture=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a set of cameras and downsample them to the region around annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create camera set\n",
    "camera_set = MetashapeCameraSet(CAMERA_FILENAME, IMAGE_FOLDER)\n",
    "# Extract cameras near the training data\n",
    "# TODO consider how to do the same thing with a mesh\n",
    "training_camera_set = camera_set.get_subset_near_geofile(\n",
    "    UPDATED_GEO_FILNAME, buffer_radius_meters=BUFFER_RADIUS_METER\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the mesh and read texture from geopolygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = TexturedPhotogrammetryMesh(\n",
    "    DOWNSAMPLED_MESH_FILENAME,\n",
    "    texture=UPDATED_GEO_FILNAME,\n",
    "    texture_kwargs={\"column_name\": \"species_observed\"},\n",
    "    transform_filename=CAMERA_FILENAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter the labels based on height above ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_texture = mesh.get_texture()\n",
    "ground_mask = mesh.get_height_above_ground(DEM_file=DEM_FILE,threshold=HEIGHT_ABOVE_GROUND_THRESH)\n",
    "ground_mask_faces = mesh.vert_to_face_texture(ground_mask)\n",
    "\n",
    "label_names = mesh.get_label_names()\n",
    "is_labeled = face_texture[:,0] >= 0\n",
    "is_labeled_and_ground = np.logical_and(is_labeled, ground_mask_faces)\n",
    "\n",
    "# Set a new ground class only for ground that would otherwise be tree\n",
    "face_texture[is_labeled_and_ground, 0] = len(label_names)\n",
    "mesh.set_texture(face_texture)\n",
    "mesh.set_label_names(label_names.tolist() + [\"GROUND\"])\n",
    "mesh.save_mesh(LABELED_MESH_FILENAME, save_vert_texture=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh.vis(mesh_kwargs={\"cmap\": \"tab10\", \"clim\": [0, 9]}, camera_set=training_camera_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render the labels onto the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh.save_renders_pytorch3d(\n",
    "    camera_set=training_camera_set, render_image_scale=RENDER_IMAGE_SCALE, save_native_resolution=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiview-prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
