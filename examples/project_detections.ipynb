{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from imageio import imread\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyvista as pv\n",
    "import rasterio as rio\n",
    "from shapely import Point\n",
    "\n",
    "from geograypher.cameras import MetashapeCameraSet\n",
    "from geograypher.constants import DATA_FOLDER, INSTANCE_ID_KEY, LAT_LON_CRS\n",
    "from geograypher.entrypoints.project_detections import project_detections\n",
    "from geograypher.predictors.derived_segmentors import TabularRectangleSegmentor\n",
    "from geograypher.utils.visualization import create_pv_plotter\n",
    "from geograypher.utils.parsing import parse_transform_metashape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data folder on Google Drive should be placed in the `data` subfolder of the repository\n",
    "DETECTIONS_DATA_FOLDER = Path(DATA_FOLDER, \"example_detection\")\n",
    "INPUT_FOLDER = Path(DETECTIONS_DATA_FOLDER, \"inputs\")\n",
    "INTERMEDIATE_FOLDER = Path(DETECTIONS_DATA_FOLDER, \"intermediate_results\")\n",
    "OUTPUT_FOLDER = Path(DETECTIONS_DATA_FOLDER, \"outputs\")\n",
    "\n",
    "# Path to cameras\n",
    "CAMERAS_FILENAME = Path(INPUT_FOLDER, \"hidden_little_cameras.xml\")\n",
    "# Path to mesh\n",
    "MESH_FILENAME = Path(INPUT_FOLDER, \"hidden_little_mesh.ply\")\n",
    "# Path to images\n",
    "IMAGE_FOLDER = Path(INPUT_FOLDER, \"images\")\n",
    "# Path to detection predictions\n",
    "DETECTIONS_FOLDER = Path(INPUT_FOLDER, \"detections\")\n",
    "# Path to orthomosaic\n",
    "ORTHO_FILENAME = Path(INPUT_FOLDER, \"hidden_little_ortho.tif\")\n",
    "\n",
    "# Path to saved projections onto the face. Can either be read from or written to depending on the step\n",
    "PROJECTIONS_TO_MESH_FILENAME = Path(INTERMEDIATE_FOLDER, \"projections_to_mesh.npz\")\n",
    "# File to export the geospatial projections to\n",
    "PROJECTIONS_TO_GEOSPATIAL_SAVEFILENAME = Path(\n",
    "    OUTPUT_FOLDER, \"detections_projected_to_geospatial.geojson\"\n",
    ")\n",
    "# File to export the triangulated points to\n",
    "TRIANGULATED_POINTS_SAVEFILE = Path(\n",
    "    OUTPUT_FOLDER, \"detections_triangulated_to_geospatial.geojson\"\n",
    ")\n",
    "\n",
    "# Focal length of the camera in pixels\n",
    "DEFAULT_FOCAL_LENGTH = 8688\n",
    "# Whether to run the step for projecting images to meshes\n",
    "PROJECT_TO_MESH = True\n",
    "# Whether to run the conversion from mesh to geospatial\n",
    "CONVERT_TO_GEOSPATIAL = True\n",
    "# Whether to show the mesh\n",
    "VIS_MESH = True\n",
    "# Whether to show the geospatial predictions\n",
    "VIS_GEODATA = True\n",
    "\n",
    "# Keyword arguments for the segmentor\n",
    "SEGMENTOR_KWARGS = {\n",
    "    \"image_path_key\": \"image_path\",\n",
    "    \"label_key\": \"instance_ID\",\n",
    "    \"split_bbox\": False,\n",
    "}\n",
    "# For the ray-based approach, the tolerance between detections to consider them a match\n",
    "RAY_BASED_SIMILARITY_THRESHOLD_METERS = 0.25\n",
    "# The resolution parameter of networkx.louvain_communities.\n",
    "# https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.community.louvain.louvain_communities.html\n",
    "# higher values favor smaller clusters of detections corresponding to one bird\n",
    "LOUVAIN_RESOLUTION = 2\n",
    "# The length in meters of the lines for visualizing the rays\n",
    "VIS_RAY_LENGTH_METERS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projection detections to mesh\n",
    "Here we take the per-image detections and project them onto the faces of the mesh. If requested, these projections can be visualized and/or saved to a file for further processing. Note that you could also could convert them to geospatial coordinates using this function, but it's split into two function calls to demonstrate the functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_detections(\n",
    "    mesh_filename=MESH_FILENAME,\n",
    "    cameras_filename=CAMERAS_FILENAME,\n",
    "    image_folder=IMAGE_FOLDER,\n",
    "    detections_folder=DETECTIONS_FOLDER,\n",
    "    projections_to_mesh_filename=PROJECTIONS_TO_MESH_FILENAME,\n",
    "    projections_to_geospatial_savefilename=PROJECTIONS_TO_GEOSPATIAL_SAVEFILENAME,\n",
    "    default_focal_length=DEFAULT_FOCAL_LENGTH,\n",
    "    project_to_mesh=PROJECT_TO_MESH,\n",
    "    segmentor_kwargs=SEGMENTOR_KWARGS,\n",
    "    vis_mesh=VIS_MESH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert mesh projections to geospatial\n",
    "In the previous step, the per-image detections were projected to the mesh. Now, they are converted to a 2D, geospatial representation. This can be visualized and/or exported as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_detections(\n",
    "    mesh_filename=MESH_FILENAME,\n",
    "    cameras_filename=CAMERAS_FILENAME,\n",
    "    image_folder=IMAGE_FOLDER,\n",
    "    detections_folder=DETECTIONS_FOLDER,\n",
    "    projections_to_mesh_filename=PROJECTIONS_TO_MESH_FILENAME,\n",
    "    projections_to_geospatial_savefilename=PROJECTIONS_TO_GEOSPATIAL_SAVEFILENAME,\n",
    "    convert_to_geospatial=CONVERT_TO_GEOSPATIAL,\n",
    "    segmentor_kwargs=SEGMENTOR_KWARGS,\n",
    "    vis_geodata=VIS_GEODATA,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the orthomosaic generated for this site and optionally detections\n",
    "For assessment, the detections are shown overlaid on the orthomosaic. Both the orthomosaic and exported detections are in geospatial coordinates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the orthomosaic\n",
    "ortho = rio.open(ORTHO_FILENAME)\n",
    "\n",
    "# Create axes for consistency between the two data products\n",
    "_, ax = plt.subplots()\n",
    "# Note this can take a while for large rasters, I'm not sure there's a way to downsample using this function\n",
    "rio.plot.show(ortho, ax=ax)\n",
    "\n",
    "# If there are projections, visualize those too\n",
    "if PROJECTIONS_TO_GEOSPATIAL_SAVEFILENAME is not None and PROJECTIONS_TO_GEOSPATIAL_SAVEFILENAME.exists():\n",
    "    # Read the file\n",
    "    projected_detections = gpd.read_file(PROJECTIONS_TO_GEOSPATIAL_SAVEFILENAME)\n",
    "    print(projected_detections)\n",
    "    # Convert to the same CRS as the ortho\n",
    "    projected_detections.to_crs(ortho.crs, inplace=True)\n",
    "    # Plot the detections colored by the detection ID\n",
    "    # This corresponding to their index in the ordered set of all detections\n",
    "    projected_detections.plot(INSTANCE_ID_KEY, facecolor=\"none\", ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternate approach using triangulation \n",
    "This approach does not use the mesh for estimating the 3D locations of the birds. Instead, it casts rays in the direction of the center of each detection. Then, it identifies clusters of pairwise near-intersections between rays as likely locations of birds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of cameras\n",
    "camera_set = MetashapeCameraSet(\n",
    "    camera_file=CAMERAS_FILENAME,\n",
    "    image_folder=IMAGE_FOLDER,\n",
    "    default_sensor_params={\"cx\": 0, \"cy\": 0, \"f\": DEFAULT_FOCAL_LENGTH}\n",
    ")\n",
    "\n",
    "# Determine the shape of the images, assuming they're all the same\n",
    "image_shape = imread(list(IMAGE_FOLDER.glob(\"*.JPG\"))[0]).shape[:2]\n",
    "\n",
    "# Create a detector object that looks up detections from a folder. The predictions should be\n",
    "# one per image in the DeepForest format.\n",
    "detector = TabularRectangleSegmentor(\n",
    "    detection_file_or_folder=DETECTIONS_FOLDER,\n",
    "    image_folder=IMAGE_FOLDER,\n",
    "    image_shape=image_shape,\n",
    "    **SEGMENTOR_KWARGS\n",
    ")\n",
    "\n",
    "# Create a pyvista plotter to show both scenes at once\n",
    "plotter = create_pv_plotter(off_screen=False, force_xvfb=False)\n",
    "\n",
    "# Load the mesh and plot it\n",
    "mesh = pv.read(MESH_FILENAME)\n",
    "plotter.add_mesh(mesh, rgb=True)\n",
    "\n",
    "# Extract the transform to global coordinates from the cameras filename\n",
    "transform_to_epsg_4978 = parse_transform_metashape(CAMERAS_FILENAME)\n",
    "\n",
    "# Identify correspondences between detections and show them\n",
    "detected_bird_locations = camera_set.triangulate_detections(\n",
    "    detector=detector,\n",
    "    transform_to_epsg_4978=transform_to_epsg_4978,\n",
    "    similarity_threshold_meters=RAY_BASED_SIMILARITY_THRESHOLD_METERS,\n",
    "    louvain_resolution=LOUVAIN_RESOLUTION,\n",
    "    plotter=plotter,\n",
    "    vis_ray_length_meters=VIS_RAY_LENGTH_METERS,\n",
    ")\n",
    "# Show the cameras\n",
    "camera_set.vis(show=True, frustum_scale=0.5, plotter=plotter)\n",
    "\n",
    "# TODO convert these into geospatial coords\n",
    "print(f\"{len(detected_bird_locations)} birds were detected at the following 3D locations, in (lat, lon, alt) coordinates:\\n{detected_bird_locations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exported the triangulated locations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the array to a list of shapely points. Note that the first two coordinates must be\n",
    "# switched because of different conventions between pyproj and geopandas\n",
    "points = [Point(l[1], l[0], l[2]) for l in detected_bird_locations]\n",
    "# Create a dataframe\n",
    "points_gdf = gpd.GeoDataFrame(geometry=points, crs=LAT_LON_CRS)\n",
    "# Export the dataframe\n",
    "points_gdf.to_file(TRIANGULATED_POINTS_SAVEFILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the triangulated locations over the ortho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the orthomosaic\n",
    "ortho = rio.open(ORTHO_FILENAME)\n",
    "\n",
    "# Create axes for consistency between the two data products\n",
    "_, ax = plt.subplots()\n",
    "# Note this can take a while for large rasters, I'm not sure there's a way to downsample using this function\n",
    "rio.plot.show(ortho, ax=ax)\n",
    "\n",
    "# If there are projections, visualize those too\n",
    "if TRIANGULATED_POINTS_SAVEFILE is not None and TRIANGULATED_POINTS_SAVEFILE.exists():\n",
    "    # Read the file\n",
    "    triangulated_detections = gpd.read_file(TRIANGULATED_POINTS_SAVEFILE)\n",
    "    # Convert to the same CRS as the ortho\n",
    "    triangulated_detections.to_crs(ortho.crs)\n",
    "    # Show each triangulated point\n",
    "    triangulated_detections.plot(markersize=5, ax=ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geograypher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
