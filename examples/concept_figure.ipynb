{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.transform import Rotation\n",
    "from imageio import imwrite\n",
    "\n",
    "\n",
    "from geograypher.constants import MATPLOTLIB_PALLETE, VIS_FOLDER\n",
    "from geograypher.utils.example_data import (\n",
    "    create_non_overlapping_points,\n",
    "    create_scene_mesh,\n",
    ")\n",
    "from geograypher.cameras.cameras import PhotogrammetryCameraSet\n",
    "from geograypher.meshes.meshes import TexturedPhotogrammetryMesh\n",
    "from geograypher.predictors.derived_segmentors import LookUpSegmentor\n",
    "from geograypher.utils.visualization import show_segmentation_labels\n",
    "from geograypher.cameras.segmentor import (\n",
    "    SegmentorPhotogrammetryCameraSet,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to save content\n",
    "CONCEPT_FIGURE_ROOT = Path(VIS_FOLDER, \"concept_figure_content\")\n",
    "IMAGE_FOLDER = Path(CONCEPT_FIGURE_ROOT, \"realistic_images\")\n",
    "FIGURES_SAVE_FOLDER = Path(CONCEPT_FIGURE_ROOT, \"figures\")\n",
    "LABEL_IMAGES_FOLDER = Path(CONCEPT_FIGURE_ROOT, \"labeled_images\")\n",
    "\n",
    "# Save vis or show them in the notebook\n",
    "SAVE_VIS = True\n",
    "\n",
    "# Number of map elements\n",
    "N_BOXES = 5\n",
    "N_CYLINDERS = 5\n",
    "N_CONES = 5\n",
    "# Random seed for object locations\n",
    "MAP_RANDOM_SEED = 42 #1029\n",
    "# Discritization of the ground plane\n",
    "GROUND_RESOLUTION = 200\n",
    "# Scale of the frustum\n",
    "VIS_FRUSTUM_SCALE = 1\n",
    "\n",
    "# Mapping from integer IDs to human-readable labels\n",
    "IDS_TO_LABELS = {0: \"cone\", 1: \"cube\", 2: \"cylinder\"}\n",
    "\n",
    "# Range of hues for each object\n",
    "HUE_RANGE_DICT = {\"cone\": 0.1, \"cylinder\": 0.2, \"cube\": 0.1}\n",
    "# Only used for realist\n",
    "REALISTIC_COLOR_DICT = {\n",
    "    \"cone\": MATPLOTLIB_PALLETE[0],\n",
    "    \"cylinder\": MATPLOTLIB_PALLETE[2],\n",
    "    \"cube\": MATPLOTLIB_PALLETE[1],\n",
    "}\n",
    "\n",
    "# Camera set params\n",
    "CAM_HEIGHT = 10\n",
    "CAM_DIST_FROM_CENTER = 10\n",
    "CAM_PITCH = 225\n",
    "\n",
    "CAM_INTRINSICS = {\n",
    "    0: {\"f\": 4000, \"cx\": 0, \"cy\": 0, \"image_width\": 3000, \"image_height\": 2200}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = create_non_overlapping_points(\n",
    "    n_points=(N_BOXES + N_CYLINDERS + N_CONES), random_seed=MAP_RANDOM_SEED\n",
    ")\n",
    "\n",
    "mesh, labels_gdf = create_scene_mesh(\n",
    "    box_centers=points[:N_BOXES],\n",
    "    cylinder_centers=points[N_BOXES : (N_BOXES + N_CYLINDERS)],\n",
    "    cone_centers=points[(N_BOXES + N_CYLINDERS) : (N_BOXES + N_CYLINDERS + N_CONES)],\n",
    "    add_ground=True,\n",
    "    ground_resolution=GROUND_RESOLUTION,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the colors for the \"realistic\" views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_color_gradient(color, number, hue_range=None):\n",
    "    if hue_range is None:\n",
    "        hue_range = 1 / (number * 2)\n",
    "\n",
    "    hsv_color = matplotlib.colors.rgb_to_hsv(color)\n",
    "    hue_start = hsv_color[0] - hue_range / 2\n",
    "    hue_end = hsv_color[0] + hue_range / 2\n",
    "    hues = np.linspace(hue_start, hue_end, number) % 1.0\n",
    "    shifted_HSVs = [np.concatenate(([hue], hsv_color[1:]), axis=0) for hue in hues]\n",
    "    rgb_values = [\n",
    "        matplotlib.colors.hsv_to_rgb(shifted_hue) for shifted_hue in shifted_HSVs\n",
    "    ]\n",
    "    rgb_values = np.vstack(rgb_values)\n",
    "\n",
    "    rgb_values = rgb_values / 255.0\n",
    "\n",
    "    return rgb_values\n",
    "\n",
    "\n",
    "colors_per_face = np.full((mesh.n_cells, 3), fill_value=0.5)\n",
    "IDs_per_face = np.full((mesh.n_cells, 1), fill_value=np.nan)\n",
    "\n",
    "for i, (name, group) in enumerate(labels_gdf.groupby(\"name\")):\n",
    "    num = len(group)\n",
    "    gradient = make_color_gradient(\n",
    "        REALISTIC_COLOR_DICT[name], num, hue_range=HUE_RANGE_DICT[name]\n",
    "    )\n",
    "    # Indices into the original dataset\n",
    "    IDs = group.index.to_numpy()\n",
    "    # TODO rename\n",
    "    for ID, color in zip(IDs, gradient):\n",
    "        matching = mesh[\"ID\"] == ID\n",
    "        colors_per_face[matching, :] = color\n",
    "        IDs_per_face[matching, :] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the 2D map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_gdf.plot(\"name\", legend=True, cmap=\"tab10\", vmin=0, vmax=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a set of virtual cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create translations\n",
    "t_vecs = (\n",
    "    (0, 0, CAM_HEIGHT),\n",
    "    (0, CAM_DIST_FROM_CENTER, CAM_HEIGHT),\n",
    "    (CAM_DIST_FROM_CENTER, 0, CAM_HEIGHT),\n",
    "    (-CAM_DIST_FROM_CENTER, 0, CAM_HEIGHT),\n",
    "    (0, -CAM_DIST_FROM_CENTER, CAM_HEIGHT),\n",
    ")\n",
    "# Create rotations in roll, pitch, yaw convention\n",
    "r_vecs = (\n",
    "    (180, 180, 0),  # nadir\n",
    "    (180, CAM_PITCH, 0),  # oblique\n",
    "    (90, CAM_PITCH, 0),  # oblique\n",
    "    (270, CAM_PITCH, 0),  # oblique\n",
    "    (0, CAM_PITCH, 0),  # oblique\n",
    ")\n",
    "\n",
    "# Create 4x4 transforms\n",
    "cam_to_world_transforms = []\n",
    "for r_vec, t_vec in zip(r_vecs, t_vecs):\n",
    "    r_mat = Rotation.from_euler(\"ZXY\", r_vec, degrees=True).as_matrix()\n",
    "    transform = np.eye(4)\n",
    "    transform[:3, :3] = r_mat\n",
    "    transform[:3, 3] = t_vec\n",
    "    cam_to_world_transforms.append(transform)\n",
    "\n",
    "IMAGE_FOLDER.mkdir(exist_ok=True, parents=True)\n",
    "# Note that these files do not exist yet, but will be later created\n",
    "image_filenames = [Path(IMAGE_FOLDER, f\"img_{i:03d}.png\") for i in range(5)]\n",
    "\n",
    "camera_set = PhotogrammetryCameraSet(\n",
    "    cam_to_world_transforms=cam_to_world_transforms,\n",
    "    intrinsic_params_per_sensor_type=CAM_INTRINSICS,\n",
    "    image_folder=IMAGE_FOLDER,\n",
    "    image_filenames=image_filenames,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a colored mesh with a \"realistic\" textuer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realistic_mesh = TexturedPhotogrammetryMesh(mesh, texture=colors_per_face)\n",
    "realistic_mesh.vis(\n",
    "    force_xvfb=True,\n",
    "    camera_set=camera_set,\n",
    "    screenshot_filename=Path(FIGURES_SAVE_FOLDER, \"realistic_scene.png\"),\n",
    "    frustum_scale=VIS_FRUSTUM_SCALE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a mesh textured with the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_mesh = TexturedPhotogrammetryMesh(\n",
    "    mesh,\n",
    "    texture=IDs_per_face,\n",
    "    IDs_to_labels=IDS_TO_LABELS,\n",
    ")\n",
    "labeled_mesh.vis(\n",
    "    force_xvfb=True,\n",
    "    camera_set=camera_set,\n",
    "    screenshot_filename=Path(FIGURES_SAVE_FOLDER, \"labeled_scene.png\"),\n",
    "    frustum_scale=VIS_FRUSTUM_SCALE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render from the camera viewpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGURES_SAVE_FOLDER.mkdir(exist_ok=True, parents=True)\n",
    "LABEL_IMAGES_FOLDER.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "label_renders_gen = labeled_mesh.render_flat(camera_set)\n",
    "flat_texture_render_gen = realistic_mesh.render_flat(camera_set)\n",
    "realistic_render_gen = realistic_mesh.render_flat(camera_set)\n",
    "\n",
    "for i, (label_render, flat_texture_render, realistic_render) in tqdm(\n",
    "        enumerate(\n",
    "            zip(label_renders_gen, flat_texture_render_gen, realistic_render_gen)\n",
    "        ),\n",
    "        total=5\n",
    "    ):\n",
    "\n",
    "    # Save out an integer label image\n",
    "    label_render_for_saving = np.squeeze(label_render.copy())\n",
    "    label_render_for_saving[np.logical_not(np.isfinite(label_render_for_saving))] = 255\n",
    "    label_render_for_saving = label_render_for_saving.astype(np.uint8)\n",
    "\n",
    "    imwrite(Path(LABEL_IMAGES_FOLDER, f\"img_{i:03d}.png\"), label_render_for_saving)\n",
    "    # Save out the rendered \"realistic imager\"\n",
    "    image_path = camera_set.get_image_filename(i, absolute=True)\n",
    "    imwrite(image_path, (realistic_render*255).astype(np.uint8))\n",
    "\n",
    "    # Save or vis the figures\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(flat_texture_render)\n",
    "\n",
    "    if SAVE_VIS:\n",
    "        plt.savefig(Path(FIGURES_SAVE_FOLDER, f\"texture_render_flat_{i:03d}.png\"))\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(\n",
    "        label_render,\n",
    "        cmap=\"tab10\",\n",
    "        vmin=0,\n",
    "        vmax=9,\n",
    "        interpolation=\"none\",\n",
    "    )\n",
    "    if SAVE_VIS:\n",
    "        plt.savefig(Path(FIGURES_SAVE_FOLDER, f\"class_render_flat{i:03d}.png\"))\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(realistic_render)\n",
    "    if SAVE_VIS:\n",
    "        plt.savefig(Path(FIGURES_SAVE_FOLDER, f\"texture_render_realistic_{i:03d}.png\"))\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show rendered labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_segmentation_labels(\n",
    "    label_folder=LABEL_IMAGES_FOLDER,\n",
    "    image_folder=IMAGE_FOLDER,\n",
    "    num_show=5,\n",
    "    image_suffix=\".png\",\n",
    "    IDs_to_labels=IDS_TO_LABELS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a segmentor that looks up labeled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentor = LookUpSegmentor(IMAGE_FOLDER, LABEL_IMAGES_FOLDER, num_classes=3)\n",
    "segmentor_camera_set = SegmentorPhotogrammetryCameraSet(camera_set, segmentor)\n",
    "aggregation_mesh = TexturedPhotogrammetryMesh(mesh=mesh, IDs_to_labels=IDS_TO_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show which faces were projected onto at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections_gen = aggregation_mesh.project_images(segmentor_camera_set)\n",
    "\n",
    "for i, faces_texture in tqdm(enumerate(projections_gen), total=5):\n",
    "    is_finite = np.any(np.isfinite(faces_texture), axis=1)\n",
    "\n",
    "    aggregation_mesh.vis(\n",
    "        vis_scalars=is_finite.astype(int),\n",
    "        camera_set=segmentor_camera_set.get_subset_cameras([i]),\n",
    "        screenshot_filename=Path(\n",
    "            FIGURES_SAVE_FOLDER, f\"view_shadows_scene_{i:03d}.png\"\n",
    "        ),\n",
    "        frustum_scale=VIS_FRUSTUM_SCALE,\n",
    "        IDs_to_labels={0: \"invisible\", 1: \"visible\"},\n",
    "    )\n",
    "\n",
    "    max_class = np.argmax(faces_texture, axis=1).astype(float)\n",
    "    max_class[np.logical_not(is_finite)] = np.nan\n",
    "    max_class[np.sum(faces_texture, axis=1)==0] = np.nan\n",
    "    segmentor_camera_set.get_subset_cameras([i])\n",
    "    aggregation_mesh.vis(\n",
    "        vis_scalars=max_class,\n",
    "        camera_set=segmentor_camera_set.get_subset_cameras([i]),\n",
    "        force_xvfb=True,\n",
    "        screenshot_filename=Path(\n",
    "            FIGURES_SAVE_FOLDER, f\"aggregated_predicted_scene_{i:03d}.png\"\n",
    "        ),\n",
    "        frustum_scale=VIS_FRUSTUM_SCALE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show aggregated viewpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    averaged_projection, additional_information\n",
    ") = aggregation_mesh.aggregate_projected_images(segmentor_camera_set)\n",
    "\n",
    "max_class = np.argmax(averaged_projection, axis=1).astype(float)\n",
    "zeros_mask = additional_information[\"projection_counts\"]  == 0\n",
    "max_class[zeros_mask] = np.nan\n",
    "aggregation_mesh.vis(\n",
    "    vis_scalars=max_class,\n",
    "    force_xvfb=True,\n",
    "    screenshot_filename=Path(FIGURES_SAVE_FOLDER, \"aggregated_predicted_scene.png\"),\n",
    "    frustum_scale=VIS_FRUSTUM_SCALE,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MVMT-dev2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
