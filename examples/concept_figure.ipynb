{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.spatial import ConvexHull\n",
    "from shapely import Polygon\n",
    "from geopandas import GeoDataFrame\n",
    "from multiview_mapping_toolkit.cameras.cameras import PhotogrammetryCameraSet\n",
    "from multiview_mapping_toolkit.meshes.meshes import TexturedPhotogrammetryMesh\n",
    "from scipy.spatial.transform import Rotation\n",
    "from multiview_mapping_toolkit.config import MATPLOTLIB_PALLETE\n",
    "from multiview_mapping_toolkit.config import VIS_FOLDER\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_non_overlapping_points(\n",
    "    n_points, distance_thresh=1, size=10, random_seed=None\n",
    "):\n",
    "    np.random.seed(random_seed)\n",
    "    all_points = (np.random.rand(1, 2) - 0.5) * size\n",
    "    while all_points.shape[0] < n_points:\n",
    "        new_point = (np.random.rand(1, 2) - 0.5) * size\n",
    "\n",
    "        dist_from_existing = cdist(new_point, all_points)\n",
    "        if np.min(dist_from_existing) > distance_thresh:\n",
    "            all_points = np.concatenate((all_points, new_point), axis=0)\n",
    "\n",
    "    return all_points\n",
    "\n",
    "\n",
    "def extract_polygon(mesh: pv.PolyData):\n",
    "    xy_points = mesh.points[:, :2]\n",
    "    hull = ConvexHull(xy_points)\n",
    "    return Polygon(xy_points[hull.vertices])\n",
    "\n",
    "\n",
    "def make_color_gradient(color, number, hue_range=None):\n",
    "    if hue_range is None:\n",
    "        hue_range = 1 / (number * 2)\n",
    "\n",
    "    hsv_color = matplotlib.colors.rgb_to_hsv(color)\n",
    "    hue_start = hsv_color[0] - hue_range / 2\n",
    "    hue_end = hsv_color[0] + hue_range / 2\n",
    "    hues = np.linspace(hue_start, hue_end, number) % 1.0\n",
    "    shifted_HSVs = [np.concatenate(([hue], hsv_color[1:]), axis=0) for hue in hues]\n",
    "    rgb_values = [\n",
    "        matplotlib.colors.hsv_to_rgb(shifted_hue) for shifted_hue in shifted_HSVs\n",
    "    ]\n",
    "    rgb_values = np.vstack(rgb_values)\n",
    "\n",
    "    rgb_values = rgb_values / 255.0\n",
    "\n",
    "    return rgb_values\n",
    "\n",
    "\n",
    "def create_scene_mesh(\n",
    "    box_centers=(),\n",
    "    cylinder_centers=(),\n",
    "    cone_centers=(),\n",
    "    cylinder_radius=0.5,\n",
    "    cone_radius=0.5,\n",
    "    box_size=1 / np.sqrt(2.0),\n",
    "    grid_size=(20, 20),\n",
    "    add_ground=True,\n",
    "):\n",
    "    box_meshes = []\n",
    "    box_polygons = []\n",
    "    ID = 0.0\n",
    "    for x, y in box_centers:\n",
    "        x_min = x - box_size / 2.0\n",
    "        x_max = x + box_size / 2.0\n",
    "        y_min = y - box_size / 2.0\n",
    "        y_max = y + box_size / 2.0\n",
    "\n",
    "        box = pv.Box((x_min, x_max, y_min, y_max, 0, box_size), quads=False)\n",
    "        box[\"ID\"] = np.full(box.n_cells, fill_value=ID)\n",
    "        box_meshes.append(box)\n",
    "        box_polygons.append(extract_polygon(box))\n",
    "        ID += 1.0\n",
    "\n",
    "    cylinder_meshes = []\n",
    "    cylinder_polygons = []\n",
    "    for x, y in cylinder_centers:\n",
    "        cylinder = pv.Cylinder(\n",
    "            (x, y, 0.5), direction=(0, 0, 1), radius=cylinder_radius, resolution=10\n",
    "        ).triangulate()\n",
    "        cylinder[\"ID\"] = np.full(cylinder.n_cells, fill_value=ID)\n",
    "        cylinder_meshes.append(cylinder)\n",
    "        cylinder_polygons.append(extract_polygon(cylinder))\n",
    "        ID += 1.0\n",
    "\n",
    "    cone_meshes = []\n",
    "    cone_polygons = []\n",
    "    for x, y in cone_centers:\n",
    "        cone = pv.Cone(\n",
    "            (x, y, 0.5),\n",
    "            direction=(0, 0, -1),\n",
    "            radius=cone_radius,\n",
    "            resolution=12,\n",
    "        ).triangulate()\n",
    "        cone[\"ID\"] = np.full(cone.n_cells, fill_value=ID)\n",
    "        cone_meshes.append(cone)\n",
    "        cone_polygons.append(extract_polygon(cone))\n",
    "        ID += 1.0\n",
    "\n",
    "    merged_mesh = pv.merge(box_meshes + cylinder_meshes + cone_meshes)\n",
    "    labels_gdf = GeoDataFrame(\n",
    "        {\n",
    "            \"name\": [\"cube\"] * len(box_meshes)\n",
    "            + [\"cylinder\"] * len(cylinder_meshes)\n",
    "            + [\"cone\"] * len(cone_meshes)\n",
    "        },\n",
    "        geometry=box_polygons + cylinder_polygons + cone_polygons,\n",
    "    )\n",
    "\n",
    "    if add_ground:\n",
    "        # Add the ground plane\n",
    "        object_points = merged_mesh.points[np.isclose(merged_mesh.points[:, 2], 0)]\n",
    "        grid_size_x, grid_size_y = grid_size\n",
    "        # Add the corner points of the ground plane\n",
    "        grid = np.meshgrid(\n",
    "            np.linspace(-grid_size_x / 2, grid_size_x / 2, num=100),\n",
    "            np.linspace(-grid_size_y / 2, grid_size_y / 2, num=100),\n",
    "        )\n",
    "        grid = [x.flatten() for x in grid]\n",
    "        ground_points = np.vstack(grid + [np.zeros_like(grid[0])]).T\n",
    "\n",
    "        ground_points = pv.PolyData(ground_points)\n",
    "        object_points = pv.PolyData(object_points)\n",
    "        combined = object_points + ground_points\n",
    "        # Triangulate between all the vertices\n",
    "        ground_surf = (combined).delaunay_2d()\n",
    "        # Set the ID to nan\n",
    "        ground_surf[\"ID\"] = np.full(ground_surf.n_cells, fill_value=np.nan)\n",
    "        # Merge the ground plane with the other actors\n",
    "        merged_mesh = merged_mesh + ground_surf\n",
    "    return merged_mesh, labels_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to save content\n",
    "CONCEPT_FIGURE_ROOT = Path(VIS_FOLDER, \"concept_figure_content\")\n",
    "\n",
    "# Save vis or show them in the notebook\n",
    "SAVE_VIS = False\n",
    "\n",
    "# Number of map elements\n",
    "N_BOXES = 5\n",
    "N_CYLINDERS = 5\n",
    "N_CONES = 5\n",
    "# Random seed for object locations\n",
    "MAP_RANDOM_SEED = 42\n",
    "\n",
    "# Range of hues for each object\n",
    "HUE_RANGE_DICT = {\"cone\": 0.1, \"cylinder\": 0.2, \"cube\": 0.1}\n",
    "# Only used for realist\n",
    "REALISTIC_COLOR_DICT = {\n",
    "    \"cone\": MATPLOTLIB_PALLETE[0],\n",
    "    \"cylinder\": MATPLOTLIB_PALLETE[2],\n",
    "    \"cube\": MATPLOTLIB_PALLETE[1],\n",
    "}\n",
    "\n",
    "# Camera set params\n",
    "CAM_HEIGHT = 10\n",
    "CAM_DIST_FROM_CENTER = 10\n",
    "CAM_PITCH = 225\n",
    "\n",
    "CAM_INTRINSICS = {\n",
    "    0: {\"f\": 4000, \"cx\": 0, \"cy\": 0, \"image_width\": 3000, \"image_height\": 2200}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = create_non_overlapping_points(\n",
    "    n_points=(N_BOXES + N_CYLINDERS + N_CONES), random_seed=MAP_RANDOM_SEED\n",
    ")\n",
    "\n",
    "mesh, labels_gdf = create_scene_mesh(\n",
    "    box_centers=points[:N_BOXES],\n",
    "    cylinder_centers=points[N_BOXES : (N_BOXES + N_CYLINDERS)],\n",
    "    cone_centers=points[(N_BOXES + N_CYLINDERS) : (N_BOXES + N_CYLINDERS + N_CONES)],\n",
    "    add_ground=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the colors for the \"realistic\" views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_per_face = np.full((mesh.n_cells, 3), fill_value=0.5)\n",
    "IDs_per_face = np.full((mesh.n_cells, 1), fill_value=np.nan)\n",
    "\n",
    "for i, (name, group) in enumerate(labels_gdf.groupby(\"name\")):\n",
    "    num = len(group)\n",
    "    gradient = make_color_gradient(\n",
    "        REALISTIC_COLOR_DICT[name], num, hue_range=HUE_RANGE_DICT[name]\n",
    "    )\n",
    "    # Indices into the original dataset\n",
    "    IDs = group.index.to_numpy()\n",
    "    # TODO rename\n",
    "    for ID, color in zip(IDs, gradient):\n",
    "        matching = mesh[\"ID\"] == ID\n",
    "        colors_per_face[matching, :] = color\n",
    "        IDs_per_face[matching, :] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the 2D map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_gdf.plot(\"name\", legend=True, cmap=\"tab10\", vmin=0, vmax=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Create a set of virtual cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_vecs = (\n",
    "    (0, 0, CAM_HEIGHT),\n",
    "    (0, CAM_DIST_FROM_CENTER, CAM_HEIGHT),\n",
    "    (CAM_DIST_FROM_CENTER, 0, CAM_HEIGHT),\n",
    "    (-CAM_DIST_FROM_CENTER, 0, CAM_HEIGHT),\n",
    "    (0, -CAM_DIST_FROM_CENTER, CAM_HEIGHT),\n",
    ")\n",
    "ROLL_SHIFT = 180\n",
    "# Roll, pitch, yaw convention\n",
    "r_vecs = (\n",
    "    (0 + ROLL_SHIFT, 180, 0),\n",
    "    (0 + ROLL_SHIFT, CAM_PITCH, 0),\n",
    "    (270 + ROLL_SHIFT, CAM_PITCH, 0),\n",
    "    (90 + ROLL_SHIFT, CAM_PITCH, 0),\n",
    "    (180 + ROLL_SHIFT, CAM_PITCH, 0),\n",
    ")\n",
    "\n",
    "cam_to_world_transforms = []\n",
    "for r_vec, t_vec in zip(r_vecs, t_vecs):\n",
    "    r_mat = Rotation.from_euler(\"ZXY\", r_vec, degrees=True).as_matrix()\n",
    "    transform = np.eye(4)\n",
    "    transform[:3, :3] = r_mat\n",
    "    transform[:3, 3] = t_vec\n",
    "    cam_to_world_transforms.append(transform)\n",
    "\n",
    "IMAGE_FOLDER = Path(CONCEPT_FIGURE_ROOT, \"realistic_images\")\n",
    "IMAGE_FOLDER.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "IMAGE_FILENAMES = [Path(IMAGE_FOLDER, f\"img_{i:03d}.png\") for i in range(5)]\n",
    "\n",
    "camera_set = PhotogrammetryCameraSet(\n",
    "    cam_to_world_transforms=cam_to_world_transforms,\n",
    "    intrinsic_params_per_sensor_type=CAM_INTRINSICS,\n",
    "    image_folder=IMAGE_FOLDER,\n",
    "    image_filenames=IMAGE_FILENAMES,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a colored mesh with a \"realistic\" textuer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realistic_mesh = TexturedPhotogrammetryMesh(mesh, texture=colors_per_face)\n",
    "realistic_mesh.vis(force_xvfb=True, camera_set=camera_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a mesh textured with the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_mesh = TexturedPhotogrammetryMesh(\n",
    "    mesh, texture=IDs_per_face, texture_column_name=\"name\"\n",
    ")\n",
    "labeled_mesh.vis(\n",
    "    force_xvfb=True,\n",
    "    camera_set=camera_set,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from imageio import imwrite\n",
    "\n",
    "FIGURE_SAVE_FOLDER = Path(CONCEPT_FIGURE_ROOT, \"figures\")\n",
    "FIGURE_SAVE_FOLDER.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "LABEL_IMAGES_FOLDER = Path(CONCEPT_FIGURE_ROOT, \"labeled_images\")\n",
    "LABEL_IMAGES_FOLDER.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "for i in range(5):\n",
    "    # Do the three types of rendering\n",
    "    label_render = labeled_mesh.render_pytorch3d(\n",
    "        camera_set,\n",
    "        i,\n",
    "        shade_by_indexing=True,\n",
    "    )\n",
    "    flat_texture_render = realistic_mesh.render_pytorch3d(\n",
    "        camera_set, i, shade_by_indexing=True\n",
    "    )\n",
    "    realistic_render = realistic_mesh.render_pyvista(camera_set, i, enable_ssao=True)\n",
    "\n",
    "    # Save out an integer label image\n",
    "    label_render_for_saving = label_render.copy()\n",
    "    label_render_for_saving[np.logical_not(np.isfinite(label_render_for_saving))] = 255\n",
    "    label_render_for_saving = label_render_for_saving.astype(np.uint8)\n",
    "    imwrite(Path(LABEL_IMAGES_FOLDER, f\"img_{i:03d}.png\"), label_render_for_saving)\n",
    "    # Save out the rendered \"realistic imager\"\n",
    "    image_path = camera_set.get_image_filename(i, absolute=True)\n",
    "    imwrite(image_path, realistic_render)\n",
    "\n",
    "    # Save or vis the figures\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(flat_texture_render, (0, 1))\n",
    "\n",
    "    if SAVE_VIS:\n",
    "        plt.savefig(Path(FIGURE_SAVE_FOLDER, f\"texture_render_flat_{i:03d}.png\"))\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(\n",
    "        label_render,\n",
    "        cmap=\"tab10\",\n",
    "        vmin=0,\n",
    "        vmax=9,\n",
    "        interpolation=\"none\",\n",
    "    )\n",
    "    if SAVE_VIS:\n",
    "        plt.savefig(Path(FIGURE_SAVE_FOLDER, f\"class_render_flat{i:03d}.png\"))\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(realistic_render)\n",
    "    if SAVE_VIS:\n",
    "        plt.savefig(Path(FIGURE_SAVE_FOLDER, f\"texture_render_realistic_{i:03d}.png\"))\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiview_mapping_toolkit.segmentation.derived_segmentors import LookUpSegmentor\n",
    "from multiview_mapping_toolkit.segmentation.segmentor import (\n",
    "    SegmentorPhotogrammetryCameraSet,\n",
    ")\n",
    "\n",
    "segmentor = LookUpSegmentor(IMAGE_FOLDER, LABEL_IMAGES_FOLDER, num_classes=3)\n",
    "segmentor_camera_set = SegmentorPhotogrammetryCameraSet(camera_set, segmentor)\n",
    "aggregation_mesh = TexturedPhotogrammetryMesh(mesh=mesh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_camera_set = segmentor_camera_set.get_subset_cameras([1])\n",
    "(\n",
    "    normalized_face_texture,\n",
    "    face_texture,\n",
    "    counts,\n",
    ") = aggregation_mesh.aggregate_viewpoints_pytorch3d(sub_camera_set)\n",
    "aggregation_mesh.vis(vis_scalars=counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    sub_camera_set = segmentor_camera_set.get_subset_cameras([i])\n",
    "    (\n",
    "        normalized_face_texture,\n",
    "        face_texture,\n",
    "        counts,\n",
    "    ) = aggregation_mesh.aggregate_viewpoints_pytorch3d(sub_camera_set)\n",
    "    max_class = np.argmax(face_texture, axis=1).astype(float)\n",
    "    zeros_mask = np.sum(face_texture, axis=1) == 0\n",
    "    max_class[zeros_mask] = np.nan\n",
    "    aggregation_mesh.vis(\n",
    "        vis_scalars=max_class,\n",
    "        force_xvfb=True,\n",
    "        mesh_kwargs={\"cmap\": \"tab10\", \"clim\": (0, 9)},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show aggregated viewpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    normalized_face_texture,\n",
    "    face_texture,\n",
    "    counts,\n",
    ") = aggregation_mesh.aggregate_viewpoints_pytorch3d(segmentor_camera_set)\n",
    "max_class = np.argmax(face_texture, axis=1).astype(float)\n",
    "zeros_mask = np.sum(face_texture, axis=1) == 0\n",
    "max_class[zeros_mask] = np.nan\n",
    "aggregation_mesh.vis(\n",
    "    vis_scalars=max_class,\n",
    "    force_xvfb=True,\n",
    "    mesh_kwargs={\"cmap\": \"tab10\", \"clim\": (0, 9)},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MVMT-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
