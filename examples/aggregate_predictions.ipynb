{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pprint\n",
    "\n",
    "from geograypher.cameras.derived_cameras import MetashapeCameraSet\n",
    "from geograypher.cameras.segmentor import SegmentorPhotogrammetryCameraSet\n",
    "from geograypher.meshes import TexturedPhotogrammetryMesh\n",
    "from geograypher.predictors.derived_segmentors import LookUpSegmentor\n",
    "from geograypher.utils.prediction_metrics import compute_and_show_cf, compute_comprehensive_metrics\n",
    "from geograypher.utils.indexing import find_argmax_nonzero_value\n",
    "from geograypher.utils.visualization import show_segmentation_labels\n",
    "from geograypher.constants import (\n",
    "    EXAMPLE_CAMERAS_FILENAME,\n",
    "    EXAMPLE_MESH_FILENAME,\n",
    "    EXAMPLE_IMAGE_FOLDER,\n",
    "    EXAMPLE_LABELS_FILENAME,\n",
    "    EXAMPLE_PREDICTED_LABELS_FOLDER,\n",
    "    EXAMPLE_DTM_FILE,\n",
    "    EXAMPLE_AGGREGATED_FACE_LABELS_FILE,\n",
    "    EXAMPLE_PREDICTED_VECTOR_LABELS_FILE,\n",
    "    EXAMPLE_IDS_TO_LABELS,\n",
    "    EXAMPLE_LABEL_COLUMN_NAME,\n",
    "    TEN_CLASS_VIS_KWARGS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip re-computing the aggregation and use a saved version\n",
    "USE_CACHED_AGGREGATION = False\n",
    "# Processing parameters\n",
    "HEIGHT_ABOVE_GROUND_THRESH = 2  # Height above the DTM to consider not ground\n",
    "MESH_DOWNSAMPLE_TARGET = 0.25  # Downsample the mesh to this fraction\n",
    "AGGREGATE_IMAGE_SCALE = 0.25  # Aggregate images at this scale resolution\n",
    "BUFFER_RADIUS_METER = 50  # Include cameras within this radius of labeled points\n",
    "MESH_VIS_KWARGS = TEN_CLASS_VIS_KWARGS\n",
    "\n",
    "LABEL_COLUMN_NAME = EXAMPLE_LABEL_COLUMN_NAME\n",
    "IDS_TO_LABELS = EXAMPLE_IDS_TO_LABELS\n",
    "CAMERAS_FILENAME = EXAMPLE_CAMERAS_FILENAME\n",
    "MESH_FILENAME = EXAMPLE_MESH_FILENAME\n",
    "IMAGE_FOLDER = EXAMPLE_IMAGE_FOLDER\n",
    "LABELS_FILENAME = EXAMPLE_LABELS_FILENAME\n",
    "PREDICTED_IMAGE_LABELS_FOLDER = EXAMPLE_PREDICTED_LABELS_FOLDER\n",
    "DTM_FILE = EXAMPLE_DTM_FILE\n",
    "AGGREGATED_FACE_LABELS_FILE = EXAMPLE_AGGREGATED_FACE_LABELS_FILE\n",
    "PREDICTED_VECTOR_LABELS_FILE = EXAMPLE_PREDICTED_VECTOR_LABELS_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = TexturedPhotogrammetryMesh(\n",
    "    MESH_FILENAME,\n",
    "    transform_filename=EXAMPLE_CAMERAS_FILENAME,\n",
    "    IDs_to_labels=IDS_TO_LABELS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the camera set and subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create camera set\n",
    "camera_set = MetashapeCameraSet(CAMERAS_FILENAME, IMAGE_FOLDER)\n",
    "# Extract cameras near the training data\n",
    "camera_set = camera_set.get_subset_ROI(\n",
    "    ROI=LABELS_FILENAME, buffer_radius=BUFFER_RADIUS_METER\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_set.vis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh.vis(camera_set=camera_set, force_xvfb=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the per-image predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_segmentation_labels(label_folder=PREDICTED_IMAGE_LABELS_FOLDER, image_folder=IMAGE_FOLDER, IDs_to_labels=IDS_TO_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentor = LookUpSegmentor(\n",
    "    base_folder=IMAGE_FOLDER,\n",
    "    lookup_folder=PREDICTED_IMAGE_LABELS_FOLDER,\n",
    "    num_classes=len(mesh.get_label_names()),\n",
    ")\n",
    "\n",
    "segmentor_camera_set = SegmentorPhotogrammetryCameraSet(\n",
    "    camera_set, segmentor=segmentor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_CACHED_AGGREGATION:\n",
    "    aggregated_face_labels = np.load(AGGREGATED_FACE_LABELS_FILE)\n",
    "else:\n",
    "    aggregated_face_labels, _ = mesh.aggregate_projected_images(\n",
    "        segmentor_camera_set,\n",
    "        aggregate_img_scale=AGGREGATE_IMAGE_SCALE,\n",
    "    )\n",
    "    np.save(AGGREGATED_FACE_LABELS_FILE, aggregated_face_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_face_classes = find_argmax_nonzero_value(aggregated_face_labels, keepdims=True)\n",
    "predicted_face_classes = mesh.label_ground_class(\n",
    "    labels=predicted_face_classes,\n",
    "    height_above_ground_threshold=HEIGHT_ABOVE_GROUND_THRESH,\n",
    "    DTM_file=DTM_FILE,\n",
    "    ground_ID=np.nan,\n",
    "    set_mesh_texture=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the projected and aggregated face predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh.vis(vis_scalars=predicted_face_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the mesh predictions to generate per-polygon labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "polygons = gpd.read_file(LABELS_FILENAME)\n",
    "# Assign a label to each polygon using the mesh faces that overlap with it\n",
    "predicted_polygon_labels = mesh.label_polygons(\n",
    "    face_labels=predicted_face_classes,\n",
    "    polygons=polygons\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the ground truth classes\n",
    "ground_truth_labeling = polygons[LABEL_COLUMN_NAME]\n",
    "# Get all the possible classes, in case you wanted to compare across sites where only\n",
    "# a subset of all classes were present at one\n",
    "# Drop the ground class because no polygons are labeled that\n",
    "all_classes = list(IDS_TO_LABELS.values())[:-1]\n",
    "# Compute the confusion matrix\n",
    "cf_matrix, _, accuracy = compute_and_show_cf(\n",
    "    pred_labels=predicted_polygon_labels,\n",
    "    gt_labels=ground_truth_labeling,\n",
    "    labels=all_classes\n",
    ")\n",
    "print(f\"Accuracy was {accuracy}\")\n",
    "# Compute more detailed metrics from the confusion matrix\n",
    "comprehensive_metrics = compute_comprehensive_metrics(\n",
    "    cf_matrix=cf_matrix,\n",
    "    class_names=all_classes\n",
    ")\n",
    "# Format and print the dict\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "print(\"Comprehensive metrics:\")\n",
    "print(pp.pprint(comprehensive_metrics))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MVMT-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
